# Eco-Mentos Front/Back/RAG/AI 구현 정리

이 문서는 Eco-Mentos 프로젝트에서 구축한 프론트엔드, 백엔드, RAG, AI Core의 기능과 구현 방식을 정리한 기술 개요입니다. 각 섹션은 실제 코드 위치와 함께 주요 설계 포인트를 요약합니다.

## 1. 프론트엔드 (Next.js / TypeScript)
- Next.js 13 App Router 기반 단일 페이지에서 경제 지수, 챗봇, 히스토리 UI를 통합한다 (`frontend/src/app/page.tsx:81`).
- React Query로 지수와 데일리 인사이트를 캐싱·재시도하며 10~15분 TTL을 적용한다 (`frontend/src/app/page.tsx:63`, `frontend/src/lib/api.ts:19`).
- 스트리밍 질문 처리는 커스텀 훅이 AbortController와 NDJSON 파서를 관리하며 메트릭과 메타 정보를 누적한다 (`frontend/src/hooks/useAskStream.ts:29`, `frontend/src/lib/api.ts:41`).
- 사용자가 보낸 질문과 답변 스냅샷은 로컬스토리지에 최대 50개까지 저장해 히스토리 패널에서 재활용한다 (`frontend/src/app/page.tsx:94`, `frontend/src/lib/history.ts:17`).
- SparkChart 컴포넌트는 Recharts를 이용해 3개월 시계열과 일간 변동을 시각화하고 AI 인사이트 설명을 함께 노출한다 (`frontend/src/components/SparkChart.tsx:40`).
- DailyTerm 컴포넌트는 `/api/daily` 프록시를 호출해 경제 용어를 프리페치하고 로컬 인덱스를 순환 저장한다 (`frontend/src/components/DailyTerm.tsx:1`).

### 동작 흐름
- 사용자가 질문을 입력하면 `useAskStream` 훅이 `/ask/stream`에 POST 요청을 보내고 NDJSON 스트림을 실시간으로 카드 목록에 반영한다 (`frontend/src/hooks/useAskStream.ts:62`).
- 응답 완료 시 메타 정보에서 선택된 역할과 실행 모드를 추출해 UI 배지를 갱신하고, 초안을 히스토리에 저장한다 (`frontend/src/app/page.tsx:137`).
- 페이지 로딩 시 React Query가 지수와 인사이트를 불러오고, 로컬스토리지에서 질문 히스토리를 복구해 사이드 패널에서 재실행을 지원한다 (`frontend/src/app/page.tsx:141`, `frontend/src/components/HistoryPanel.tsx:1`).

## 2. 백엔드 (Express / TypeScript)
- `backend/src/index.ts:1`에서 Express 앱을 초기화하고 `/ask`, `/timeseries`, `/insight`, `/health` 라우트를 등록하며 JSON 본문을 1MB로 제한한다.
- `/ask` 엔드포인트는 질문을 전처리해 역할 시퀀스와 실행 모드를 확정하고, RAG 검색 → 역할별 초안 생성 → 편집자 통합 순으로 요청을 파이프라인화한다 (`backend/src/routes/ask.ts:94`, `backend/src/routes/ask.ts:144`).
- 역할 선택기는 정규식 매칭과 LLM 기반 플래너를 결합해 `eco/firm/house` 조합을 결정하고 허용된 시퀀스만 유지한다 (`backend/src/routes/ask.ts:59`, `backend/src/routes/ask.ts:200`).
- 스트리밍 버전 `/ask/stream`은 초안 생성 단계에서 카드 내용을 줄 단위로 분리해 NDJSON 이벤트로 전송하고, 완료 시 메트릭과 타임스탬프를 포함한다 (`backend/src/routes/ask.ts:217`).
- `/timeseries` 라우트는 내부 Market API에 대한 프록시로, 캐시된 KOSPI/IXIC 데이터를 가져와 프론트엔드에 전달한다 (`backend/src/routes/timeseries.ts:9`).
- `/insight/daily` 라우트는 네이버 뉴스 검색, 시계열 데이터, 에디터 모델을 조합해 요약·카드를 생성하고 실패 시 기본 규칙 기반 결과로 폴백한다 (`backend/src/routes/insight.ts:1`).

### 주요 구현 포인트
- 모든 AI 호출은 `provider_local`을 통해 역할별 LoRA 엔드포인트를 선택하고, 메타 데이터에 실제 사용된 베이스 URL을 기록한다 (`backend/src/ai/provider_local.ts:8`).
- 초안 생성과 편집자 단계는 공통 프롬프트 유틸을 사용해 일관된 마크다운 구조와 한국어 출력을 강제한다 (`backend/src/ai/prompts.ts:1`).
- 요청당 선택된 RAG 근거는 카드의 `sources` 필드로 삽입돼 UI에서 근거 라벨링을 할 수 있게 한다 (`backend/src/ai/bridge.ts:77`).

## 3. RAG 레이어 (Node.js 내장)
- RAG 데이터는 역할별 JSONL 파일로 관리하며 `backend/data/rag/*.jsonl`에 저장한다 (예: `backend/data/rag/eco.jsonl`).
- `searchRAG` 함수는 질문 토큰을 생성하고, 역할별 상위 k개 문서를 스코어링해 매칭 네임스페이스(`macro/firm/household`)별로 상위 결과를 반환한다 (`backend/src/ai/rag.ts:58`).
- 스코어는 토큰 커버리지, 태그 매칭, 최신성, 출처 신뢰도, 요약 길이 패널티를 조합해 계산하며, 결과는 근거 텍스트와 메타 정보를 포함한다 (`backend/src/ai/rag.ts:96`).
- 데이터셋은 서버 시작 시 메모리에 적재되고, 없는 경우 경고를 남겨 개발 중에도 유연하게 동작한다 (`backend/src/ai/rag.ts:40`).
- Market API에서 받은 KOSPI/IXIC 시계열과 뉴스 검색 결과도 인사이트 생성 시 보조 증거로 활용된다 (`backend/src/routes/insight.ts:6`).

## 4. AI Core (Python / FastAPI)
- `ai/main.py:16`은 역할별 기본 포트를 정의하고 환경 변수나 충돌 상황에 따라 가용 포트를 동적으로 탐색한다.
- 실행 시 역할별 LoRA 경로를 등록하고, 각 역할마다 독립 프로세스에서 FastAPI 서버를 띄워 `/chat` 엔드포인트를 제공한다 (`ai/main.py:38`, `ai/server_base.py:117`).
- 서버는 RBLN 컴파일 모델과 Torch 백엔드를 모두 지원하며, RBLN 사용 시에도 토큰화/디코딩이 일관되도록 처리한다 (`ai/server_base.py:64`).
- 요청마다 메시지 템플릿을 적용해 프롬프트를 구성하고, 최대 토큰·온도 파라미터를 제어하며 필요한 경우 LoRA 어댑터를 핫스왑한다 (`ai/server_base.py:89`, `ai/server_base.py:128`).
- `/chat` 응답은 불필요한 내부 추론을 제거한 텍스트만 반환하며, 백엔드가 카드 구조를 재구성한다 (`backend/src/ai/bridge.ts:60`).

### 운영 메모
- `run.sh` 스크립트는 Market API, AI Core, 백엔드, 프론트엔드를 한 번에 기동하며 로그는 `logs/` 폴더에 저장된다 (`README.md:120`).
- 환경 변수 `ECO_AI_BASE`, `FIRM_AI_BASE`, `HOUSE_AI_BASE`, `EDITOR_AI_BASE` 등을 통해 외부 모델 엔드포인트로도 라우팅할 수 있다 (`backend/src/ai/provider_local.ts:18`).

## 5. 통합 데이터 흐름 요약
- 프론트엔드가 `/ask/stream`을 호출하면 백엔드는 RAG 근거와 AI Core 초안을 사용해 카드 묶음을 스트리밍한다.
- 동시에 `/timeseries`와 `/insight/daily` 호출로 지수 차트와 오늘의 해설을 갱신하고, 사용자는 히스토리 패널에서 이전 대화를 재실행할 수 있다.
- 전체 파이프라인은 역할별 LoRA 모델과 JSONL 근거를 기반으로 경제·기업·가계 시각을 구분해 설명하는 데 초점을 맞춘다.
